## 肺部可视化大作业

### 概述

此项目旨在通过数据可视化技术实现对肺部结构的可视化，并提供相应的交互界面。以下是项目的技术选型和实现细节。

### 技术选型

- **nii数据处理**：
  - nii数据读取：使用nibabel库
  - nii数据3D可视化：利用PyVista库
  - 肺部分割：nnUNet

- **前后端实现**：
  - 前端：采用React框架
  - 后端：采用Express.js

### 启动说明

#### 安装必要的node.js包

安装node.js（安装教程自行查阅）

1. 进入frontend文件夹
2. 运行
   ```bash
   npm install
   ```
3. 进入server文件夹，重复步骤2

#### 启动React前端：

1. 打开命令行终端。
2. 进入React前端项目根目录（通常为`frontend`文件夹）。
3. 输入以下命令启动React应用：
   ```bash
   npm start
   ```
4. 按回车键，React应用将会开始构建并在默认浏览器中打开。

#### 启动Express后端：

1. 打开另一个命令行终端。
2. 进入Express后端项目根目录（通常为`server`文件夹）。
3. 输入以下命令启动Express服务器：
   ```bash
   node app.js
   ```
启动后，React前端应用将会在3000端口上运行，Express后端应用将会在5000端口上运行。你可以通过访问`http://localhost:3000`查看网页。

### 实现细节

#### nnUNet 详细介绍

##### 概述

nnUNet，全称“No New U-Net”，是一个针对医学图像分割任务的深度学习框架。它设计为一种“无超参数”的解决方案，旨在减少配置深度学习模型时的复杂性。nnUNet在各种医学图像分割挑战中表现出色，成为许多研究和临床应用中的首选工具。

##### 核心特点

1. **自适应性强**：nnUNet能够根据不同的任务和数据集自动配置模型架构和训练参数，无需手动调参。
2. **全自动化流程**：包括预处理、数据增强、模型训练、推理和后处理，极大地简化了用户操作。
3. **跨模态支持**：支持2D、3D、2.5D等多种数据输入模式，适用于不同维度和模态的医学影像数据。

##### 工作流程

1. **数据预处理**：
   - **数据规范化**：包括对比度归一化、体素间距统一等操作。
   - **数据增强**：通过旋转、翻转、裁剪等方法增加数据量，提高模型的泛化能力。

2. **模型架构**：
   - **2D U-Net**：适用于2D切片数据。
   - **3D U-Net**：适用于3D体数据。其中包含3D_fullres和3D_lowres两种模式

3. **训练过程**：
   - 使用交叉熵损失函数和Dice损失函数。
   - 采用Adam优化器，动态调整学习率。
   - 支持多种数据增强策略，提高模型的鲁棒性。

4. **推理与后处理**：
   - 在推理阶段，使用滑动窗口技术处理大尺寸图像。
   - 后处理步骤包括连通组件分析、体素分类修正等，提升分割结果的准确性。

#### 数据集

本项目使用COVID-19-CT-Seg数据集，该数据集包含了COVID-19患者的CT扫描图像，标注了左肺、右肺和感染区域。

- **数据集下载地址**： [COVID-19-CT-Seg](https://zenodo.org/record/3757476#.Xpz8OcgzZPY)
- **模态类型**：CT图像
- **类别**：
  - 0: 背景
  - 1: 左肺
  - 2: 右肺
  - 3: 感染区域

#### 模型训练

1. **参数设置**：
   - **模态设置**：2d
   - **批次大小**：8
   - **模态数量**：1
   - **训练模式**：5折交叉训练

2. **训练过程**：
   - **数据增强**：对训练数据进行旋转、缩放、平移等操作。
   - **模型保存**：每一折训练完成后，保存最佳模型权重。
   每折训练曲线见train_loss文件夹

#### 推理

使用训练好的nnUNet模型对新的CT图像进行推理，生成包含左肺、右肺和病灶区域的分割掩码。推理结果以nii文件格式保存。

#### 模型与图像生成

运行initialize.py，脚本将通过使用推理后的掩码图像，并使用多进程快速为每一个病人生成灰度CT图，掩码CT图和模型。

#### 3D显示

#### 1. 读取和处理数据

- **读取nii文件**：
  使用nibabel库读取CT图像和肺部区域掩码文件，并获取数据数组。

- **处理掩码数据**：
  获取肺部掩码数据，其中掩码值1和2代表左肺和右肺区域。

#### 2. 提取和处理肺部区域

- **提取肺部区域**：
  创建肺部掩码，只保留掩码值为1和2的部分。

- **去除空的层**：
  移除空的层，减少不必要的计算量。

- **应用掩码提取肺部**：

#### 3. 将3D numpy数组转换为pyvista的UnstructuredGrid对象

- **降采样**：
  使用scipy.ndimage库对数据进行降采样，以减少计算量和内存使用。

- **简化网格**：
  使用`decimate_pro`方法对生成的3D网格进行简化，降低渲染复杂度。

- **Marching Cubes算法生成网格**：
  使用scikit-image库的Marching Cubes算法生成3D表面网格。

- **调整顶点位置和简化网格**：
  调整顶点位置以反映层间距，并使用pyvista库的`decimate_pro`方法简化网格，减少顶点和面数以提高渲染效率。

#### 4. 生成和导出3D模型

- **创建Plotter对象并添加肺部网格**：
  使用pyvista库创建3D绘图对象，并添加肺部网格，应用平滑算法以提高视觉效果。

- **处理和添加新冠感染区域**：
   处理方式同上

- **导出为HTML文件**：
  将生成的3D模型导出为HTML文件，方便展示。


### 文件详解

- **generate_lesions_json.py**: 从nnUNet分割后的nii文件中提取病灶区域的层索引，并将这些层索引保存到一个JSON文件中。
- **generate_gray_image.py**: 从nii文件中提取每一层的图像，并将这些图像保存为灰度图（jpg格式）。
- **generate_masked_img.py**: 读取nii文件，将肺部区域的掩码（以及病灶区域的掩码）叠加在原始CT图像上，并将每一层保存为带有颜色掩码的图像（jpg格式）。
- **generate_model_html.py**: 使用基于VTK的PyVista库生成3D模型，并生成对应的HTML文件用于在浏览器中展示模型。
- **initialize.py**: 使用多进程池并行处理多个nii文件，生成灰度图、带掩码图像、病灶层指示JSON文件和3D模型HTML文件。
- **frontend文件夹**: 存放网页所用到的组件和样式文件。在文件夹中，src/components目录下存放了构建网页所用到的组件（Component），其中，MainComponent控制所有组件的布局，IFrameViewer负责展示模型,ImageDisplay展示灰度CT图像和识别肺部及感染区域后的CT图像,SelectionControls控制所有的选择框，按钮以及选项内容，WelcomeModal负责展示进入网页后的使用指南和注意事项。styles.css储存网页的布局信息。其他部分则为React项目创建后的必备内容，包括主控组件（入口）App.js和其对应的样式表App.css。其他在此不赘述。
- **server文件夹**: 后端程序Express.js的启动入口和路由规则文件。其中，app.js是后端程序Express.js的启动入口，也存放了所有的路由规则，访问调取文件函数等功能。前端通过访问api，api返回所请求的内容来显示对应内容（如图片和模型）。